# Java并发机制的底层实现原理

### volatile的应用

- volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的“可见性”。
- volatile比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。
- 本文将深入分析在硬件层面上Intel处理器是如何实现volatile的，通过深入分析帮助我们正确地使用volatile变量。

1. volatile的定义与实现原理
   - Java语言规范第3版中对volatile的定义如下：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。
   - 如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。
   - 在了解volatile实现原理之前，我们先来看下与其实现原理相关的CPU术语与说明。
   - ![CPU的术语定义](img/1.png?raw=true)
   - volatile是如何来保证可见性的呢？让我们在X86处理器下通过工具获取JIT编译器生成的汇编指令来查看对volatile进行写操作时，CPU会做什么事情。
   - Java代码如下：

   ```Java
   instance = new Singleton(); //instance是volatile变量
   ```

   - 转变成汇编语言：

   ```汇编语言
   0x01a3de1d: movb $0×0,0×1104800(%esi);0x01a3de24: lock addl $0×0,(%esp);
   ```

   - 有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，通过查IA-32架构软件开发者手册可知，Lock前缀的指令在多核处理器下会引发了两件事情。
     1. 将当前处理器缓存行的数据写回到系统内存。
     2. 这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。


   - volatile的两条实现原则：
     1. Lock前缀指令会引起处理器缓存回写到内存。
     2. 一个处理器的缓存回写到内存会导致其他处理器的缓存无效。

2. volatile的使用优化

   - JDK 7的并发包里新增一个队列集合类LinkedTransferQueue，它在使用volatile变量时，用一种追加字节的方式来优化队列出队和入队的性能。
   - LinkedTransferQueue的代码如下。

   ```Java
   /** 队列中的头部节点 */
   private transient f?inal PaddedAtomicReference<QNode> head;
   /** 队列中的尾部节点 */
   private transient f?inal PaddedAtomicReference<QNode> tail;
   static f?inal class PaddedAtomicReference <T> extends AtomicReference T> {
   // 使用很多4个字节的引用追加到64个字节
   Object p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, pa, pb, pc, pd, pe;
   PaddedAtomicReference(T r) {
   super(r);
   }
   }
   public class AtomicReference <V> implements java.io.Serializable {
   private volatile V value;
   // 省略其他代码
   ｝
   ```

   - 追加字节能优化性能
     - LinkedTransferQueue这个类，它使用一个内部类类型来定义队列的头节点（head）和尾节点（tail），而这个内部类PaddedAtomicReference相对于父类AtomicReference只做了一件事情，就是将共享变量追加到64字节。我们可以来计算下，一个对象的引用占4个字节，它追加了15个变量（共占60个字节），再加上父类的value变量，一共64个字节。
   - 为什么追加64字节能够提高并发编程的效率呢？
     - 对于英特尔酷睿i7、酷睿、Atom和NetBurst，以及Core Solo和Pentium M处理器的L1、L2或L3缓存的高速缓存行是64个字节宽，不支持部分填充缓存行。
     - 如果队列的头节点和尾节点都不足64字节的话，处理器会将它们都读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头、尾节点，当一个处理器试图修改头节点时，会将整个缓存行锁定。
     - 那么在缓存一致性机制的作用下，会导致其他处理器不能访问自己高速缓存中的尾节点，而队列的入队和出队操作则需要不停修改头节点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率。
     - 追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存行，使头、尾节点在修改时不会互相锁定。
   - 那么是不是在使用volatile变量时都应该追加到64字节呢？
     - 在两种场景下不应该使用这种方式。
       1. 缓存行非64字节宽的处理器。
          - 如P6系列和奔腾处理器，它们的L1和L2高速缓存行是32个字节宽。
       2. 共享变量不会被频繁地写。
          - 因为使用追加字节的方式需要处理器读取更多的字节到高速缓冲区，这本身就会带来一定的性能消耗，如果共享变量不被频繁写的话，锁的几率也非常小，就没必要通过追加字节的方式来避免相互锁定。
   - 这种追加字节的方式在Java 7下可能不生效，因为Java 7变得更加智慧，它会淘汰或重新排列无用字段，需要使用其他追加字节的方式。

---

###  synchronized的实现原理与应用

- 在多线程并发编程中synchronized一直是元老级角色，很多人都会称呼它为重量级锁。
- 但是，随着Java SE 1.6对synchronized进行了各种优化之后，有些情况下它就并不那么重了。
- 本文详细介绍Java SE 1.6中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁，以及锁的存储结构和升级过程。
- 先来看下利用synchronized实现同步的基础：**Java中的每一个对象都可以作为锁。**
- 具体表现为以下3种形式。
  1. 对于普通同步方法，锁是当前实例对象。
  2. 对于静态同步方法，锁是当前类的Class对象。
  3. 对于同步方法块，锁是Synchonized括号里配置的对象。
- 当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。
- 从JVM规范中可以看到Synchonized在JVM里的实现原理，JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。
- 代码块同步是使用monitorenter和monitorexit指令实现的，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。
- monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。
- 任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。
- 线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。

##### Java对象头

- synchronized用的锁是存在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit。如下图所示：![Java对象头的长度](img/2.png?raw=true)
- Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下图所示：![Java对象头的存储结构](img/3.png?raw=true)
- 在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据，如下图所示：![Mark Word的状态变化](img/4.png?raw=true)
- 在64位虚拟机下，Mark Word是64bit大小的，其存储结构如下图所示：![Mark Word的存储结构](img/5.png?raw=true)


##### 锁的升级与对比

- Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“**偏向锁**”和“**轻量级锁**”。
- 在Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：**无锁状态**、**偏向锁状态**、**轻量级锁状态**和**重量级锁状态**，这几个状态会随着竞争情况逐渐升级。
- 锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。
- 这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。

1. **偏向锁**

   - HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。
   - 当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否
     存储着指向当前线程的偏向锁。
   - 如果测试成功，表示线程已经获得了锁。
   - 如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：
     - 如果没有设置，则使用CAS竞争锁；
     - 如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。

   1. **偏向锁的撤销**
      - 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。
      - 偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。
      - 它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；
      - 如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。
      - 下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。
      - ![偏向锁初始化的流程](img/6.png?raw=true)
   2. **关闭偏向锁**
      - 偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。
      - 如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-
        UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。

2. **轻量级锁**

   1. **轻量级锁加锁**
      - 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。
      - 然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。
      - 如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
   2. **轻量级锁解锁**
      - 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成
        功，则表示没有竞争发生。
      - 如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。
      - 下图是两个线程同时争夺锁，导致锁膨胀的流程图。
      - ![争夺锁导致的锁膨胀流程图](img/7.png?raw=true)
      - 因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。
      - 当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。

3. **锁的优缺点对比**

   - 下图是锁的优缺点的对比。![锁的优缺点的对比](img/8.png?raw=true)

---

### **原子操作的实现原理**

- 原子（*atomic*）本意是“不能被进一步分割的最小粒子”，而原子操作（*atomic operation*）意为“不可被中断的一个或一系列操作”。在多处理器上实现原子操作就变得有点复杂。

1. **术语定义**

   - 在了解原子操作的实现原理前，先要了解一下相关的术语。![CPU术语定义](img/9.png?raw=true)

2. **处理器如何实现原子操作**

   - 32位IA-32处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。
   - 首先处理器会自动保证基本的内存操作的原子性。
   - 处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。
   - Pentium 6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器是不能自动保证其原子性的，比如跨总线宽度、跨多个缓存行和跨页表的访问。
   - 但是，处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。

   1. **使用总线锁保证原子性**

      - **第一个机制是通过总线锁保证原子性。**
        - 如果多个处理器同时对共享变量进行读改写操作（i++就是经典的读改写操作），那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。
        - 举个例子，如果i=1，我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2，如下图所示：![结果对比](img/10.png?raw=true)
        - 原因可能是多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入系统内存中。
        - 那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。
        - 处理器使用总线锁就是来解决这个问题的。
        - 所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。

   2. **使用缓存锁保证原子性**

      - **第二个机制是通过缓存锁定来保证原子性。**

        - 在同一时刻，我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。
        - 频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在Pentium 6和目前的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。
        - 所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性。
        - 因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效，在如上图所示的例子中，当CPU1修改缓存行中的i时使用了缓存锁定，那么CPU2就不能同时缓存i的缓存行。

      - **但是有两种情况下处理器不会使用缓存锁定。**

        1. 第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（*cache line*）时，则处理器会调用总线锁定。
        2. 第二种情况是：有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的
           内存区域在处理器的缓存行中也会调用总线锁定。

        - 针对以上两个机制，我们通过Intel处理器提供了很多Lock前缀的指令来实现。
        - 例如：位测试和修改指令：BTS、BTR、BTC；交换指令XADD、CMPXCHG，以及其他一些操作数和逻辑指令（如ADD、OR）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。

3. **Java如何实现原子操作**

   - 在Java中可以通过锁和循环CAS的方式来实现原子操作。

   1. **使用循环CAS实现原子操作**

      - JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。
      - 自旋CAS实现的基本思路就是循环进行CAS操作直到成功为止，以下代码实现了一个基于CAS线程安全的计数器方法safeCount和一个非线程安全的计数器count。

      ```Java
      public class Counter {

          private AtomicInteger atomicI = new AtomicInteger(0);

          private Integer i = 0;

          public static void main(String[] args) {
              final Counter cas = new Counter();
              List<Thread> ts = new ArrayList<>(100);
              long start = System.currentTimeMillis();
              for (int i = 0; i < 100; i++) {
                  Thread t = new Thread(() -> {
                      for (int j = 0; j < 10000; j++) {
                          cas.count();
                          cas.safeCount();
                      }
                  });
                  ts.add(t);
              }
              ts.forEach(Thread::start);
            	//等待所有线程执行完成
              ts.forEach(t -> {
                  try {
                      t.join();
                  } catch (InterruptedException e) {
                      e.printStackTrace();
                  }
              });
              System.out.println(cas.i);
              System.out.println(cas.atomicI.get());
              System.out.println(System.currentTimeMillis() - start);
          }
        
          /**
           * 使用CAS实现线程安全计数器
           */
          public void safeCount() {
              while (true) {
                  int i = atomicI.get();
                  if (atomicI.compareAndSet(i, ++i)) {
                      break;
                  }
              }
          }

          /**
           * 非线程安全计数器
           */
          public void count() {
              i++;
          }
      }
      ```

      ```Control
      760211
      1000000
      218
      ```

   2. **CAS实现原子操作的三大问题**

      - 在Java并发包中有一些并发框架也使用了自旋CAS的方式来实现原子操作，比如LinkedTransferQueue类的Xfer方法。
      - CAS虽然很高效地解决了原子操作，但是CAS仍然存在三大问题。
      - ABA问题，循环时间长开销大，以及只能保证一个共享变量的原子操作。

      1. **ABA问题。**

         - 因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。
         - ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A→B→A就会变成1A→2B→3A。
         - 从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。
         - 这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

         ```Java
         public boolean compareAndSet(
         							V expectedReference,	//预期引用
         							V newReference,			//更新后的引用
         							int expectedStamp,		//预期标志
         							int newStamp			//更新后的标志
         )
         ```

      2. **循环时间长开销大。**

         - 自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。
         - 如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升。
         - pause指令有两个作用：
           1. 第一，它可以延迟流水线执行指令（*de-pipeline*），使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零；
           2. 第二，它可以避免在退出循环的时候因内存顺序冲突（*Memory Order Violation*）而引起CPU流水线被清空（*CPU Pipeline Flush*），从而提高CPU的执行效率。

      3. **只能保证一个共享变量的原子操作。**

         - 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。
         - 还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。
         - 比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。
         - 从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。

   3. **使用锁机制实现原子操作**

      - 锁机制保证了只有获得锁的线程才能够操作锁定的内存区域。
      - JVM内部实现了很多种锁机制，有偏向锁、轻量级锁和互斥锁。
      - 有意思的是除了偏向锁，JVM实现锁的方式都用了循环CAS，即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁，当它退出同步块的时候使用循环CAS释放锁。

